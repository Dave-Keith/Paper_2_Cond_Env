<!-- Set the theme for the figures -->
```{r theme, echo=F, include=F, paged.print=FALSE,cache =F}
theme_set(theme_few(base_size = 12))
```

<!-- First up lets make a figure one of those whole area with zoom in on area of interest.  .  -->

```{r correlation, echo=F, include=T,warning=F,echo=F,message=F,fig.width=12,fig.height=5}



```

<!-- Starting the analysis.  -->

```{r correlation, echo=F, include=T,warning=F,echo=F,message=F,fig.width=12,fig.height=5}
dat.list <- list(sst = sst.raw.dat,#chl = chl.raw.dat,mld = mld.raw.dat, 
                 bt = bt.raw.dat)
cond.list <- list(may = dat.may)
res <- NULL
n.months <- 19
for(i in 1:length(dat.list))
{
  for(j in 1:length(cond.list))
  {
    res[[paste(names(dat.list)[i],names(cond.list)[j],sep="_")]] <- cor_dat(dat = dat.list[[i]], response = cond.list[[j]],n.months = n.months,last.month =7)
  }  # end for(j in 1:length(cond.list))
} # end for(i in 1:length(dat.list))

mods <- names(res)
num.mods <- length(mods)
str.names <- c(paste(c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"),"last",sep=" "),
               paste(c("Jan","Feb","Mar","Apr","May","Jun","Jul"),"cur",sep=" "))
#may.mods <- grep(pattern="may", mods)
p1<- NULL
#pdf(file = "Figures/R2_and_correlation_for_covariates.pdf",onefile=T,width = 32, height = 8)
for(i in 1:num.mods)
{
tmp <- res[[i]]
#print(paste("R2 range=" , range(tmp$resp$r2,na.rm=T)))
#print(paste("Pearson range=" , range(tmp$resp$pearson,na.rm=T)))
#print(paste("Kendall range=" , range(tmp$resp$kendall,na.rm=T)))
print(mods[i])
print("Last year:")
LY <- res[[i]]$resp[res[[i]]$resp$start.num<13 & res[[i]]$resp$end.num < 13 & !is.na(res[[i]]$resp$p.r2.lev),]
print(LY[which(LY$r2 == max(LY$r2)),])
print("Current year:")
CY <- res[[i]]$resp[res[[i]]$resp$start.num>12 & res[[i]]$resp$end.num > 12 & !is.na(res[[i]]$resp$p.r2.lev),]
print(CY[which(CY$r2 == max(CY$r2)),])


p <- ggplot(tmp$resp, aes(end.num,start.num)) + scale_x_continuous(name= "End month", breaks=1:n.months, labels = str.names) +
     scale_y_continuous(name= "Start month", breaks=1:n.months,labels = str.names) +
     theme_classic() + theme(text = element_text(size=20),axis.text.x = element_text(angle = -30, hjust=0)) 

p1[[i]] <- p + geom_raster(aes(fill = r2)) +  scale_fill_gradientn(limits = c(0,0.7),colours=c("blue","white","red")) +
          geom_text(aes(label= p.r2.lev, angle=0,hjust=0.5,vjust=1),colour="black")+ annotate("text",x=1,y=n.months,label=mods[i])

print(p1[[i]])
# p2 <- p+ geom_raster(aes(fill = kendall)) + scale_fill_gradientn(limits = c(-0.4,0.8),colours=c("blue","white","red"))+
#          geom_text(aes(label= p.kend.lev, angle=0,hjust=0.5,vjust=1),colour="black") +  ggtitle(mods[i])

} # end for(i in 1:num.mods)
# 
# plot_grid(p1[[aug.mods[1]]], p1[[aug.mods[2]]], 
#           #p1[[aug.mods[3]]], p1[[aug.mods[4]]], 
#           align="v", nrow=length(aug.mods), rel_widths=1.5)
# plot_grid(p1[[may.mods[1]]], p1[[may.mods[2]]], 
#           #p1[[may.mods[3]]], p1[[may.mods[4]]], 
#           align="v", nrow=length(may.mods), rel_widths=1.5)

```


# May condition correlation-informed aggregations
```{r, message=F, warning=F}
#----------------------------------------------------------------------------------

############DK REVISITED... GOing to use May and the same months as used in our Xiaohan paper for SST, going to do the condition thing for the Bottom Temperature
# and what we will see is that APril BT of current year is best estimator of Condition in May, which makes lots of sense story wize
# I moved away from August condition for a few reasons and I'm still not settled on it, but reasons are 
#  1) let's just do what Xiaohan did for her paper because it is published we don't need to play around with the correlation 
#      timings (which is super subjective) and the relationship she found
#  2) May condition tends to be ever so slightly lower than August condition, so these results should be more favourable for projecting than using August condition
#       given that we know the model seems to over-estimate biomass in the projections.
#  3) The linear model we use to predict condition using the DFO sourced data is very similar to what we found with Xiaohan's data.
#  4) Downside of course is we typically use August condition for our projections, but no reason for this we can't use may for projections, just need a one liner
#       saying we'd usually use August condition for this, but use May b/c relationship is stronger... etc etc etc...

# So here we use Xiaohan's choice for SST, and BT in the current year and compare to May condition.


SST.last <- aggregate(covar ~ Year, 
                      data=sst.raw.dat[sst.raw.dat$Month %in% 1:3,], FUN = sum)
names(SST.last) <- c("Year","SST.last")

# BT.cur <- aggregate(covar ~ Year, 
#                      data=bt.raw.dat[bt.raw.dat$Month %in% 4 & 
#                                        bt.raw.dat$Year %in% sst.raw.dat$Year,], FUN = sum)
# names(BT.cur) <- c("Year","BT.cur") 
#BT.last$BT.last <-  c(NA,BT.last$BT.last[-nrow(BT.last)])

dat <- aggregate(covar ~ Year, 
                 data=sst.raw.dat[sst.raw.dat$Month %in% 1:2,], FUN = sum)
names(dat) <- c("Year","SST.cur")

dat$SST.last <-  c(NA,SST.last$SST.last[-nrow(SST.last)])

dat <- dplyr::left_join(dat, BT.cur, by="Year")
dat <- dat %>% dplyr::filter(Year < 2022)

may.dat <- dat

may.dat$Condition <- dat.may$Condition
# Also make an SST sum covar
may.dat$SST.sum <- may.dat$SST.cur + may.dat$SST.last

```



# Model selection here we've made the decision to drop BNAM from this, take Xiaohan's model, apply it to our model and let's see how it works
# Then discuss why it didn't and the implication of that for EAFM...
```{r, message=F, warning=F}
#----------------------------------------------------------------------------------
# Now we run the analyses necessary for the paper.

# Now we can omit the years we don't have data right off the top, a bit too harsh but good for model comparisons...
may.dat.comp <- na.omit(may.dat)
# Just using data up to 2019, given we didn't have 2020 surveys that'll just confuse things I think... 
may.dat.comp <- may.dat.comp %>% dplyr::filter(Year < 2020)
# correlation between sst and bt
#cor.test(may.dat.comp$SST.last, may.dat.comp$BT.cur)

may.sst.last <- lm(data=may.dat.comp, Condition ~ SST.last)
may.sst.cur <- lm(data=may.dat.comp, Condition ~ SST.cur)
#may.BT.cur <- lm(data=may.dat.comp, Condition ~ BT.cur)
summary(may.sst.last)
summary(may.sst.cur)
#summary(may.BT.cur)

may.sst.sum <- lm(data=may.dat.comp, Condition ~ SST.sum)
may.sst.sum2 <- lm(data=may.dat.comp, Condition ~ SST.last + SST.cur)
summary(may.sst.sum)
summary(may.sst.sum2)

#may.sst.sum3 <- lm(data=may.dat.comp, Condition ~ SST.last + BT.cur)
#may.sst.sum4 <- lm(data=may.dat.comp, Condition ~ SST.cur + BT.cur)
summary(may.sst.sum3)
summary(may.sst.sum4)

may.sst.int <- lm(data=may.dat.comp, Condition ~ SST.last*SST.cur)
#may.sst.int2 <- lm(data=may.dat.comp, Condition ~ SST.last*SST.cur + BT.cur)
summary(may.sst.int)
#summary(may.sst.int2)

AICctab(may.sst.last, may.sst.cur,may.sst.sum, may.sst.sum2,may.sst.int)

# SST sum wins for May so away we go...
summary(may.sst.sum2)

```


# Autocorrelation within condition

## Instructions...
The next bit is doing the autocorrelation analysis, is there autocorrelation in condition time series (that is already in my code I'm 99% sure), but then also using the last 2,5,10 year (or X years) median condition to see if any of those are decent predictors of next years condition.  I suspect using last years condition is the best and that's the 'non-environmental' predictive model we'd use to compare with the environmental model. But this will be a useful exercise to see how well using a LTM of some sort to predict condition does so we can tell industry we did all this analysis and none of it helps.
We will dial in on May. After that we pick 2-3 models and do the biomass predictions with them.  
# Decided we drop bottom temperature from this analysis, idea again is see how well the cool SST model works in real world setting.

### Original (one-year lag autocorrelation?)
```{r, message=F, echo=F}
# Now we can look at the acf of condition on GB for 1999 - 2018, issue here is the data may not be stationary so need to detrend the longer ts
# gb.may.cf <- base.cond.ts$may[base.cond.ts$year %in% 1999:2015]
gba.may.cf <- base.cond.ts$may[base.cond.ts$year %in% 1984:2019]
# gb.detrend <- resid(lm(gb.may.cf~ seq(1,length(gb.may.cf)),na.action = na.exclude))
gba.detrend <- resid(lm(gba.may.cf~ seq(1,length(gba.may.cf)),na.action = na.exclude))
acfs <- acf(gba.detrend, plot = FALSE,na.action = na.pass)
plot(acfs)
acfs <- with(acfs, data.frame(lag, acf))
# So a lag linear model...
lag.may.dat <- data.frame(Condition = gba.may.cf,Year = 1984:2019)
#lag.may.dat <- may.dat[may.dat$Year %in% 1984:2018,]
lag.may.dat$cond.covar <- c(NA,lag.may.dat$Condition[1:(nrow(lag.may.dat)-1)])
lag.may.mod <- lm(Condition ~ cond.covar,lag.may.dat)
summary(lag.may.mod)
# Finally make the NULL model
null.may.mod <- lm(Condition~1,may.dat.comp)
```

### Long term median autocorrelation? 
```{r, message=F, echo=F}
# build a function to use any number of years
lastNyears_med <- function(N){
  lag <- NULL
  for(i in (N+1):length(lag.may.dat$Condition)){
    lagged <- median(lag.may.dat$Condition[(i-N):(i-1)],na.rm=T)
    lag <- c(lag, lagged)
  }
  lag <- c(rep(NA, N), lag)
  lag.median <- cbind(lag.may.dat, lag)
  
  mod <- lm(data=lag.median, Condition ~ lag)
  
  return(list(lag.median, mod))
  
}

# I also tried rolling means, but that wasn't any better

# try 2, 5, 10 years
medyrs1 <- lastNyears_med(1)
medyrs2 <- lastNyears_med(2)
medyrs5 <- lastNyears_med(5)
medyrs10 <- lastNyears_med(10)

summary(medyrs1[[2]])
summary(medyrs2[[2]])
summary(medyrs5[[2]])
summary(medyrs10[[2]])

# The NAs are fucking me up here.
mod1 <- lm(data=medyrs1[[1]][c(11:32,34:36),], Condition ~ lag)
mod2 <- lm(data=medyrs2[[1]][c(11:32,34:36),], Condition ~ lag)
mod5 <- lm(data=medyrs5[[1]][c(11:32,34:36),], Condition ~ lag)
mod10 <- lm(data=medyrs10[[1]][c(11:32,34:36),], Condition ~ lag)

AICctab(mod1,mod2, mod5, mod10)

```


# Model fit

### Environmental model options
```{r, message=F, echo=F, warning=F, fig.width=12,fig.height=5}
p1 <- ggplot(may.dat.comp,aes(x=I(SST.cur+SST.last),y = Condition)) + geom_text(aes(label=substr(Year,3,4))) + 
                          stat_smooth(method = 'lm') + 
                          xlab("SST (Previous Year + Current Year)") + ylab("Current Year SC (grams)")

p2 <- ggplot(may.dat.comp,aes(x=SST.last,y = Condition)) + geom_text(aes(label=substr(Year,3,4))) + 
                          stat_smooth(method = 'lm') + 
                          xlab("SST Previous Year") + ylab("")

p.sc <- plot_grid(p1,p2,nrow=1)
print(p.sc)
#save_plot(plot= p.sc,filename = paste0(direct.proj,"Results/Figures/SC_models.png"),base_height = 5,base_width = 10)
#save_plot(plot=p1,filename = paste0(direct.proj,"Results/Figures/SC_sum_model.png"),base_height = 5,base_width = 5)
```

### LTM options
```{r, message=F, echo=F, warning=F, fig.width=12,fig.height=5}

p3 <- ggplot(medyrs1[[1]], aes(x=lag,y = Condition)) + geom_text(aes(label=substr(Year,3,4))) + 
                          stat_smooth(method = 'lm') + 
                          xlab("Previous year median SC (grams)") + ylab("Current Year SC (grams)")


p4 <- ggplot(medyrs2[[1]], aes(x=lag,y = Condition)) + geom_text(aes(label=substr(Year,3,4))) + 
                          stat_smooth(method = 'lm') + 
                          xlab("Previous 2-year median SC (grams)") + ylab("Current Year SC (grams)")

p5 <- ggplot(medyrs5[[1]], aes(x=lag,y = Condition)) + geom_text(aes(label=substr(Year,3,4))) + 
                          stat_smooth(method = 'lm') + 
                          xlab("Previous 5-year median SC (grams)") + ylab("")

p6 <- ggplot(medyrs10[[1]], aes(x=lag,y = Condition)) + geom_text(aes(label=substr(Year,3,4))) + 
                          stat_smooth(method = 'lm') + 
                          xlab("Previous 10-year median SC (grams)") + ylab("")

p.sc2 <- plot_grid(p3,p4,p5,p6,nrow=2)
print(p.sc2)
```

### Range of best options, so this is SST sum, SST last, and SST SC.
```{r, message=F, echo=F, warning=F, fig.width=12,fig.height=5}
p.sc3 <- plot_grid(p1,p2, p3,nrow=1)
print(p.sc3)
```

```{r, message=F, warning=F}
# Get our predicted CF and compare to the Predicted condition we actually used
may.dat.pred <- may.dat %>% dplyr::filter(Year %in% 1999:2019)
# Now I need to predict Condition for 2015, I'm going to do that using the Condition relationship 
# using the last yaer condtion model, because we can do that....
may.dat.pred$Condition[may.dat.pred$Year == 2015] <- predict(medyrs1[[2]],newdata = data.frame(lag = may.dat.pred$Condition[may.dat.pred$Year == 2014]))
# I think this is what we want for the condition offset, take last years condition and use it for this year... I think...
# may.dat.pred$CF.off <- may.dat$Condition[may.dat$Year %in% 1998:2018]
# may.dat.pred$CF.off[may.dat.pred$Year == 2016] <- may.dat.pred$Condition[may.dat.pred$Year == 2015]

may.dat.pred$CF.all <- predict(may.sst.sum2,may.dat.pred)
may.dat.pred$CF.last <- predict(may.sst.last,may.dat.pred)
#may.dat.comp$CF.BTSST <- predict(may.sst.sum3,may.dat.comp)
#may.dat.comp$CF.BT <- predict(may.BT.cur,may.dat.comp)
#all.dat$CF.used <- c(all.dat$CF[2:(nrow(all.dat))],NA)

names(may.dat.pred)[which(names(may.dat.pred)=="Year")] <- "year"
names(may.dat.pred)[which(names(may.dat.pred)=="Condition")] <- "CF"



# Now we need the SH data to get the the growth rates.
all.dat <- dplyr::left_join(may.dat.pred,sh.dat,by='year')


# Now start the growth calculations.... Here's the 'known' weight in year X based on either the May or August survey
all.dat$waa.tm1 <- all.dat$CF*(all.dat$l.fr/100)^3
#all.dat$waa.tm1.aug <- all.dat$CF.aug*(all.dat$l.fr/100)^3

# Using this years average shell height we can find the exptected shell height for the scallops in the next year
# ht = (Linf * (1-exp(-K)) + exp(-K) * height(last year))
# laa.t is the projected size of the current years scallops into next year.
all.dat$laa.t <- vonB$Linf*(1-exp(-vonB$K)) + exp(-vonB$K) * all.dat$l.fr
# The c() term in the below offsets the condition so that current year's condition slots into the previous year and repeats 
# the condition for the final year), this effectively lines up "next year's condition" with "predictied shell height next year (laa.t)
# This gets us the predicted weight of the current crop of scallops next year based on next years CF * laa.t^3
# Of course we don't have next years condition thus th last condition is simply repeated
# waa.t is using the condition from next year and the growth from next year to get next years weight
all.dat$waa.t.used <- all.dat$CF*(all.dat$laa.t/100)^3
#all.dat$waa.t.aug <-  all.dat$CF.aug*(all.dat$laa.t/100)^3 # Becuase we are assuming condition doesn't change, the Aug and May scenarios 
# Actually turn out to be identical, because all you have is the growth term in there and the conditions cancel out!


# But for the modelled data I want to use the following year data because it's the spring 1987 info 
# that we use to predict 1987 condition right.  Hurting my head!! So 1987 condition by 1986 survey size data.
all.dat$waa.t.all <- c(all.dat$CF.all[2:nrow(all.dat)],NA)*(all.dat$laa.t/100)^3
all.dat$waa.t.last <- c(all.dat$CF.last[2:nrow(all.dat)],NA)*(all.dat$laa.t/100)^3


# Here we use the current condition factor to calculate the weight next year (since we use laa.t)
# That's really the only difference between waa.t and waa.t2, waa.t uses next years condition to project growth
# what waa.t2 uses the current condition to project growth.  So that's really what we are comparing here with these
# two growth metrics isn't it, this is really just comparing impact of using current vs. future condition factor on our growth estimates.

all.dat$waa.t2 <- c(all.dat$CF[2:nrow(all.dat)],NA)*(all.dat$laa.t/100)^3 # This is the 'realized' weight next year using May data, really just 
#using the growth projection * CF for next year.
#all.dat$waa.t2.aug <- c(all.dat$CF.aug[2:nrow(all.dat)],NA)*(all.dat$laa.t/100)^3
# Now the growth, expected and realized.
#Note everything in these growth in "1986" is actually used for projections in 1987.
all.dat$g.used <- all.dat$waa.t.used/all.dat$waa.tm1 # This is the growth estimate that would have been used in the model
all.dat$g.all <- all.dat$waa.t.all/all.dat$waa.tm1 # This is the growth estimate we'd use if we used the full SST predictive model
all.dat$g.last <- all.dat$waa.t.last/all.dat$waa.tm1 # This is the growth estimate we'd use if we used the last year only SST predictive model
#all.dat$g.BT <- all.dat$waa.t.BT/all.dat$waa.tm1
#all.dat$g.BTSST <- all.dat$waa.t.BTSST/all.dat$waa.tm1
all.dat$g.actual <- all.dat$waa.t2/all.dat$waa.tm1 # This is using the actual condition factor and growing the scallops by laa.t
#all.dat$g.aug <- all.dat$waa.t2.aug/all.dat$waa.tm1.aug
# Percent differences, using g.actual as our 'real' scenario. 
all.dat$prec.g.used <- 100*(all.dat$g.used - all.dat$g.actual) / all.dat$g.actual
all.dat$prec.g.all <- 100*(all.dat$g.all - all.dat$g.actual) / all.dat$g.actual
all.dat$prec.g.last <- 100*(all.dat$g.last - all.dat$g.actual) / all.dat$g.actual
#all.dat$prec.g.BT <- 100*(all.dat$g.BT - all.dat$g.actual) / all.dat$g.actual
#all.dat$prec.g.BTSST <- 100*(all.dat$g.BTSST - all.dat$g.actual) / all.dat$g.actual


summary(all.dat$prec.g.used)
summary(all.dat$prec.g.all)
summary(all.dat$prec.g.last)
#summary(all.dat$prec.g.BT)
#summary(all.dat$prec.g.BTSST)

# Now do the same thing for the recruits.
all.dat$wk.tm1 <- all.dat$CF*(all.dat$l.r/100)^3
#all.dat$wk.tm1.aug <- all.dat$CF.aug*(all.dat$l.r/100)^3
all.dat$lk.t <- vonB$Linf*(1-exp(-vonB$K))+exp(-vonB$K)*all.dat$l.r

all.dat$wk.t.used <- all.dat$CF*(all.dat$lk.t/100)^3
all.dat$wk.t.all <- c(all.dat$CF.all[2:nrow(all.dat)],NA)*(all.dat$lk.t/100)^3
all.dat$wk.t.last <-  c(all.dat$CF.last[2:nrow(all.dat)],NA)*(all.dat$lk.t/100)^3
#all.dat$wk.t.BTSST <-  c(all.dat$CF.BTSST[2:nrow(all.dat)],NA)*(all.dat$lk.t/100)^3
#all.dat$wk.t.BT <-  c(all.dat$CF.BT[2:nrow(all.dat)],NA)*(all.dat$lk.t/100)^3
#all.dat$wk.t2.aug <- c(all.dat$CF.aug[2:nrow(all.dat)],NA)*(all.dat$lk.t/100)^3
all.dat$wk.t2 <- c(all.dat$CF[2:nrow(all.dat)],NA)*(all.dat$lk.t/100)^3


all.dat$gr.used <- all.dat$wk.t.used/all.dat$wk.tm1 # This is the growth estimate that would have been used in the model
all.dat$gr.all <- all.dat$wk.t.all/all.dat$wk.tm1 # This is the growth estimate we'd use if we used the full SST predictive model
all.dat$gr.last <- all.dat$wk.t.last/all.dat$wk.tm1 # This is the growth estimate we'd use if we used the last year only SST predictive model
#all.dat$gr.BT <- all.dat$wk.t.BT/all.dat$wk.tm1 
#all.dat$gr.BTSST <- all.dat$wk.t.BTSST/all.dat$wk.tm1 
all.dat$gr.actual <- all.dat$wk.t2/all.dat$wk.tm1 # This is using the actual condition factor and growing the scallops by laa.t
#all.dat$gr.aug <- all.dat$wk.t2.aug/all.dat$wk.tm1.aug

# Percent differences, using g.actual as our 'real' scenario
all.dat$prec.gr.used <- 100*(all.dat$gr.used - all.dat$gr.actual) / all.dat$gr.actual
all.dat$prec.gr.all <- 100*(all.dat$gr.all - all.dat$gr.actual) / all.dat$gr.actual
all.dat$prec.gr.last <- 100*(all.dat$gr.last - all.dat$gr.actual) / all.dat$gr.actual
#all.dat$prec.gr.BT <- 100*(all.dat$gr.BT - all.dat$gr.actual) / all.dat$gr.actual
#all.dat$prec.gr.BTSST <- 100*(all.dat$gr.BTSST - all.dat$gr.actual) / all.dat$gr.actual
#all.dat$prec.gr.aug <- 100*(all.dat$gr.aug - all.dat$gr.actual) / all.dat$gr.actual #  division.


summary(all.dat$prec.gr.used)
summary(all.dat$prec.gr.all)
summary(all.dat$prec.gr.last)
#summary(all.dat$prec.gr.BT)
#summary(all.dat$prec.gr.BTSST)
#summary(all.dat$prec.gr.aug)
# Pivot to long form
#all.dat.long <- all.dat %>% reshape2::melt(id.vars = 'year',value.name = 'response',variable.name = 'covar')
```

# Projections
```{r, message=F, echo=F, warning=F, fig.width=12,fig.height=10}
# So what I need to do is replace the last g and gr value in this object with the predicted number and then see how much differences
# that makes in the projection.  We can go back to like 2000 with this no problem I think.


proj.B.yr <- NULL
base.year <- 2019
scenarios <- c("BM.Current","BM.All","BM.Last","BM.Realized")
for(y in 2000:2019)
{
  pick <- base.year - y+1
  gb.out <- DD.out
  gb.out$data$NY <- gb.out$data$NY-pick
  proj.B <- data.frame("BM.Current"=rep(NA,30000),"BM.All"=rep(NA,30000),
                       "BM.Last"=rep(NA,30000),"BM.Realized" = rep(NA,30000),
                       #"BM.Aug" = rep(NA,30000),
                       "BM.Actual" = rep(NA,30000), 
                       "Prop.Current"=rep(NA,30000),"Prop.All"=rep(NA,30000),
                       "Prop.Last"=rep(NA,30000),"Prop.Realized"=rep(NA,30000),
                       #"Prop.Aug"=rep(NA,30000),
                       'year' = rep(y,30000))
  # Now run through 4 scenarios
  for(i in 1:(length(scenarios)))
  {
    # Note these are all y-1 because I put them in the year before in the above (i.e. 1986 g's are for the 1987 projection)
    if(i == 2) 
    {
      gb.out$data$g[gb.out$data$NY] <- all.dat$g.all[all.dat$year == y-1]
      gb.out$data$gR[gb.out$data$NY] <- all.dat$gr.all[all.dat$year == y-1]
    }
    if(i == 3) 
    {
      gb.out$data$g[gb.out$data$NY] <- all.dat$g.last[all.dat$year == y-1]
      gb.out$data$gR[gb.out$data$NY] <- all.dat$gr.last[all.dat$year == y-1]
    }
    if(i == 4) 
    {
      gb.out$data$g[gb.out$data$NY] <- all.dat$g.actual[all.dat$year == y-1]
      gb.out$data$gR[gb.out$data$NY] <- all.dat$gr.actual[all.dat$year == y-1]
    }  

    # if(i == 4) 
  # {
  #   gb.out$data$g[gb.out$data$NY] <- all.dat$g.aug[all.dat$year == y]
  #   gb.out$data$gR[gb.out$data$NY] <- all.dat$gr.aug[all.dat$year == y]
  # }  
  # Note that I don't need to include the projected catch here because the data for catches is for the survey
  # years and so that is all nicely accounted for in this I checked and even 2019 looks to be correct, so no
  # need to do anything here since we only run to 2019... if we had 2020 we'd probably need to get funky.
    res <- projections(gb.out, C.p=(gb.fish.dat$GBa$catch[gb.fish.dat$GBa$year == y])) # C.p = potential catches in decision table
    
    proj.B[scenarios[i]] <- as.vector(res$sims.list$B.p)
  } # end for(i in 1:4)
  proj.B["BM.Actual"] <- as.vector(gb.out$sims.list$B[,gb.out$data$NY+1]) # I want next year's result because I'm projecting forward right!
  proj.B["Prop.Current"] <- (proj.B["BM.Current"] - proj.B["BM.Actual"]) /  proj.B["BM.Actual"]
  proj.B["Prop.All"] <- (proj.B["BM.All"] - proj.B["BM.Actual"]) /  proj.B["BM.Actual"]
  proj.B["Prop.Last"] <- (proj.B["BM.Last"] - proj.B["BM.Actual"]) /  proj.B["BM.Actual"]
  proj.B["Prop.Realized"] <- (proj.B["BM.Realized"] - proj.B["BM.Actual"]) /  proj.B["BM.Actual"]

  #proj.B["Prop.Aug"] <- (proj.B["BM.Aug"] - proj.B["BM.Actual"]) /  proj.B["BM.Actual"]
  # Difference
  proj.B["Diff.Current"] <- (proj.B["BM.Current"] - proj.B["BM.Actual"]) 
  proj.B["Diff.All"] <- (proj.B["BM.All"] - proj.B["BM.Actual"]) 
  proj.B["Diff.Last"] <- (proj.B["BM.Last"] - proj.B["BM.Actual"]) 
  proj.B["Diff.Realized"] <- (proj.B["BM.Realized"] - proj.B["BM.Actual"]) 

  #proj.B["Diff.Aug"] <- (proj.B["BM.Aug"] - proj.B["BM.Actual"])
  proj.B.yr[[as.character(y)]] <- proj.B
  
} # end for(y in 1987:2018)


bm.res <- do.call('rbind',proj.B.yr)


# Now switch the data to long
all.res.long <- bm.res %>% reshape2::melt(id.var = "year")



# I don't think I want the realized method on there, it is kinda relevant but makes story complicated.
bm.res.long <-  all.res.long %>% dplyr::filter(!str_detect(variable,'Realized'), str_detect(variable,'BM'))
prop.res.long <- all.res.long %>% dplyr::filter(!str_detect(variable,'Realized'), str_detect(variable,'Prop'))
diff.res.long <- all.res.long %>% dplyr::filter(!str_detect(variable,'Realized'), str_detect(variable,'Diff'))
#bm.res.long <-  all.res.long %>% dplyr::filter(str_detect(variable,'BM'))
#prop.res.long <- all.res.long %>% dplyr::filter(str_detect(variable,'Prop'))
#diff.res.long <- all.res.long %>% dplyr::filter(str_detect(variable,'Diff'))

# SO we can model the raw data, not sure that's the best plan ever, but let's see!
# So a model...
bm.res.mod <- lm(value~variable,bm.res.long)
summary(bm.res.mod)
diff.res.mod <- lm(value~variable,diff.res.long)
summary(diff.res.mod)
#par(mfrow=c(2,2));plot(diff.res.mod)
prop.res.mod <- lm(value~variable-1,prop.res.long)
summary(prop.res.mod)
#par(mfrow=c(2,2));plot(prop.res.mod)


fit.summary <- all.res.long %>% dplyr::group_by(year,variable) %>% dplyr::summarise(median = median(value),
                                                                                   mn = mean(value),
                                                                                  uqr = quantile(value,probs=0.75,na.rm=T),
                                                                                  lqr = quantile(value,probs=0.25,na.rm=T))


# I don't think I want the realized method on there, it is kinda relevant but makes story complicated.
# It also is just about identical to the "Last" model in terms of results, so really using
# August or May data for the projection doesn't matter as it over-estimates biomass almost identically.
bm.summary <- fit.summary %>% dplyr::filter(!str_detect(variable,'Realized'), str_detect(variable,'BM'))
prop.summary <- fit.summary %>% dplyr::filter(!str_detect(variable,'Realized'), str_detect(variable,'Prop'))
diff.summary <- fit.summary %>% dplyr::filter(!str_detect(variable,'Realized'), str_detect(variable,'Diff'))
#bm.summary <- fit.summary %>% dplyr::filter(str_detect(variable,'BM'))
#prop.summary <- fit.summary %>% dplyr::filter(str_detect(variable,'Prop'))
#diff.summary <- fit.summary %>% dplyr::filter(str_detect(variable,'Diff'))


diff.summary %>% group_by(variable) %>% dplyr::summarise(m = mean(median))

# The labels for the levels...
labs <- c("Full SST Model","Previous Year SST Model","Current Method","Actual")
bm.summary$variable <- factor(bm.summary$variable,levels =c("BM.All","BM.Last","BM.Current","BM.Actual"),
                              labels = labs[c(1,2,3,4)])
prop.summary$variable <- factor(prop.summary$variable,levels =c("Prop.All","Prop.Last","Prop.Current"),#,"Prop.Aug"),
                              labels = labs[c(1,2,3)])
diff.summary$variable <- factor(diff.summary$variable,levels =c("Diff.All","Diff.Last","Diff.Current"),#,"Diff.Aug"),
                                labels = labs[c(1,2,3)])

cols <- addalpha(c("orange","darkgreen","purple","darkblue"))

# Time series plots
p.bm.ts <- ggplot(bm.summary#[bm.summary$variable %in% c("Current Method", "BT", "BTSST"),]
                  , aes(x=year,y=median/1000,color = variable, group =variable)) + geom_line(lwd=1.5) +
                #geom_ribbon(aes(x=year,ymin=lqr/1000,ymax=uqr/1000,fill=variable,group = variable),alpha = 0.5) +
                geom_line() +              
                xlab("") + ylab("Biomass (kilotonnes)") +
                scale_fill_manual(values = cols) +
                scale_color_manual(values=cols) + 
                scale_x_continuous(breaks = seq(2000,2020,by=3),limits = c(2000,2020)) +
                theme(legend.position = "top",axis.text.x=element_blank(),legend.title = element_blank())

# Grab the legend then remove it from the figure....
leg <- get_legend(p.bm.ts)
p.bm.ts <- p.bm.ts + theme(legend.position = "none")
#grobs <- ggplotGrob(p.bm.ts)$grobs
#leg <- grobs[[which(sapply(grobs, function(x) x$name) == "guide-box")]]

p.diff.ts <- ggplot(diff.summary#[diff.summary$variable %in% c("Current Method", "BT", "BTSST"),]
                    , aes(x=year,y=median/1000,color = variable, group =variable)) + geom_line(lwd=1.5) +
                #geom_ribbon(aes(x=year,ymin=lqr/1000,ymax=uqr/1000,fill=variable,group = variable),alpha = 0.5) +
  geom_line() +
                xlab("") + ylab("Difference from Actual Biomass (kilotonnes)") +
                scale_fill_manual(values = cols[1:5]) +
                scale_color_manual(values=cols[1:5]) + 
                geom_hline(yintercept = 0)+ 
                scale_x_continuous(breaks = seq(2000,2020,by=3),limits = c(2000,2020)) +
                theme(legend.position = "none",axis.text.x=element_blank())

p.prop.ts <- ggplot(prop.summary#[prop.summary$variable %in% c("Current Method", "BT", "BTSST"),]
                    , aes(x=year,y=100*median,color = variable, group =variable)) + geom_line(lwd=1.5) +
                #geom_ribbon(aes(x=year,ymin=100*lqr,ymax=100*uqr,fill=variable,group = variable),alpha = 0.5) +
    geom_line() +              
  xlab("") + ylab("Difference from Actual Biomass (%)") +
                scale_fill_manual(values = cols[1:5]) +
                scale_color_manual(values=cols[1:5]) + 
                geom_hline(yintercept = 0)+
                scale_x_continuous(breaks = seq(2000,2020,by=3),limits = c(2000,2020)) +
                theme(legend.position = "none")
              

p.ts <- plot_grid(leg,p.bm.ts,p.diff.ts,p.prop.ts,ncol=1,rel_heights = c(0.2,1,1,1))
print(p.ts)
#save_plot(plot = p.ts, filename = "D:/Github/Paper_2_Cond_Env/Results/Figures/timeseries_bm_comparision.png", base_width = 6,base_height = 10)
```

```{r, message=F, echo=F, warning=F, fig.width=12,fig.height=7}
actual <- bm.summary %>%
  filter(variable=="Actual") %>%
  rename(Actual=median) %>%
  dplyr::select(year, Actual)

bm.summary <- dplyr::left_join(bm.summary, actual)

ggplot() + geom_point(data=bm.summary[!bm.summary$variable == "Actual",], aes(median, Actual)) +
  geom_smooth(data=bm.summary[!bm.summary$variable == "Actual",], aes(median, Actual), method = "lm") +
  geom_abline(slope=1, intercept=0, lwd=1)+
  facet_wrap(~variable) + theme_bw()

## Now we can fit a model which should replace the below fun...


# So a model...
bm.mod <- lm(median~variable,bm.summary)
summary(bm.mod)
diff.mod <- lm(median~variable,diff.summary)
summary(diff.mod)
par(mfrow=c(2,2));plot(diff.mod)
prop.mod <- lm(median~variable,prop.summary)
summary(prop.mod)
par(mfrow=c(2,2));plot(prop.mod)

d.mod.pred <- data.frame(variable = unique(diff.summary$variable))
d.mod.pred$est <- predict(diff.mod,d.mod.pred)
d.mod.pred$se <- predict(diff.mod,d.mod.pred,se=T)$se.fit
d.mod.pred$uci <- d.mod.pred$est + d.mod.pred$se
d.mod.pred$lci <- d.mod.pred$est - d.mod.pred$se
# Now the proportion model...
p.mod.pred <- data.frame(variable = unique(prop.summary$variable))
p.mod.pred$est <- predict(prop.mod,p.mod.pred)
p.mod.pred$se <- predict(prop.mod,p.mod.pred,se=T)$se.fit
p.mod.pred$uci <- p.mod.pred$est + p.mod.pred$se
p.mod.pred$lci <- p.mod.pred$est - p.mod.pred$se

# Note the errorbars here are 1 SE, given how similar the results are this looks nicer with the 1 SE IMHO.
p.diff <- ggplot(d.mod.pred,  aes(x=variable,y=est/1000)) + geom_point(lwd=2) +
                                  geom_errorbar(aes(x=variable,ymin=lci/1000,ymax=uci/1000),width=0) +
                                  xlab("") + ylab("Difference from Actual Biomass (kilotonnes)") +
                                  scale_fill_manual(values = cols[1:3]) +
                                  scale_color_manual(values=cols[1:3]) + 
                                  geom_hline(yintercept = 0,linetype=2)+
                                  scale_y_continuous(breaks = seq(-3,6,by=1)) +
                                  theme(legend.title = element_blank())

p.prop <- ggplot(p.mod.pred, aes(x=variable,y=100*est)) + geom_point(lwd=2) +
                                  geom_errorbar(aes(x=variable,ymin=100*lci,ymax=100*uci),width=0) +
                                  xlab("") + ylab("Difference from Actual Biomass (%)") +
                                  scale_fill_manual(values = cols[1:3]) +
                                  scale_color_manual(values=cols[1:3]) + 
                                  geom_hline(yintercept = 0,linetype=2)+
                                  scale_y_continuous(breaks = seq(-20,40,by=5)) +
                                  theme(legend.title = element_blank())



p <- plot_grid(p.diff,p.prop,ncol=1)
print(p)
#save_plot(plot = p, filename = "D:/Github/Paper_2_Cond_Env/Results/Figures/Overall_effect.png", base_width = 6,base_height =10 )

```

```{r plots,echo=F,include=F}
over.plt <- paste0(direct.proj,"Results/Figures/overview_plot.png")
```